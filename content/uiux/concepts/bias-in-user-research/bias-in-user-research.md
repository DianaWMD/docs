---
Title: 'Bias in User Research'
Description: 'In user research, bias refers to prejudices or tendencies in researchers’ and participants’ ways of thinking that can lead to inaccurate or skewed results.'
Subjects:
  - 'Web Design'
Tags:
  - 'UI'
  - 'UX'
CatalogContent:
  - 'intro-to-ui-ux'
  - 'paths/front-end-engineer-career-path'
---

In [user research](https://www.codecademy.com/resources/docs/uiux/user-research), **bias** refers to prejudices or tendencies in researchers’ and participants’ ways of thinking that can lead to inaccurate or skewed results.

To obtain accurate, useful data, researchers must be aware of their own biases. Researchers can also work to prevent participants from displaying common biases by strategically designing their studies. When analyzing results, researchers should consider how bias may have impacted the data, especially if the data is self-reported.

### Acquiescence Bias

**Acquiescence bias** is the tendency to agree with the interviewer. In general, participants are more likely to agree than to disagree. Thus, the question should not imply that there is a "correct" answer. Instead of asking for agreement or disagreement to a predefined statement, researchers can ask users to explain their point of view.

<details open>

<summary>Example</summary>

<br>

_“Would you agree that you are satisfied with the current interface?”_ This question implies that the user is satisfied with the interface and could lead to acquiescence bias. <br>

_“How do you feel about the current interface?”_ This phrasing is open-ended, so it does not lead participants to agree with a particular sentiment. </details>

### Confirmation Bias

**Confirmation bias** is the tendency for researchers to interpret data in a way that supports their opinions and beliefs. Researchers know the study’s goal, so they might make connections that aren’t explicit in the data set based on their opinions, beliefs, or expectations on how that goal should be met.

<details open>

<summary>Example</summary>

<br>

This survey asked, “Which of the following emotions do you feel when at the airport? Please select the options below.”

![Bar Chart that displays the data from the survey question: Which of the following emotions do you feel at the airport?](https://raw.githubusercontent.com/Codecademy/docs/main/media/confirmation-bias-chart.png)

The team’s larger goal is to make a product that boosts positive feelings at the airport. Confirmation bias might mean looking at this data and only reporting findings based on the statistic “57.1 of our participants are excited when traveling at the airport.” While this is true, it ignores the other data and emotions, that 42.9% also feel anxious, confused, and frustrated. </details>

### Demand Characteristics Bias

**Demand characteristics bias** is a change in how a user answers questions due to the knowledge that they are part of a research study. If the user knows, or thinks they know, the objective of a study, this could influence their responses and behaviors.

<details open>

<summary>Example</summary>

<br>

A researcher runs a concept test to evaluate an early design idea. The participant may believe that the goal is to validate the idea so the company can move on to the development phase. This belief could influence them to try to “help” the researcher. They might provide positive feedback even if they don’t like the idea. </details>

### Framing Effect

The **framing effect** occurs when findings are presented in a way that is disingenuous. Examples of the framing effect could be excluding certain data points, using statistical measures that are skewed, or strategically phrasing an insight to imply a certain idea or opinion. Researchers should present the data in a way that accurately represents respondents’ statements.

<details open>

<summary>Example</summary>

<br>

Imagine that 20 survey respondents rated their overall approval of a certain product on a Likert scale of 1 to 5.

![Likert Scale Bar Chart that displays the data from the survey question: Approval from 1-5](https://raw.githubusercontent.com/Codecademy/docs/main/media/framing-effect.png)

The researcher reports that the average approval rate is between 2 and 3, meaning that users are slightly dissatisfied. Considering that the mean is 2.45, this is technically correct. But it is a disingenuous finding &mdash; only 25% of the users actually rated the product between a 2 and a 3.

It would be more accurate to report that the majority of users are either extremely dissatisfied or extremely satisfied with the product. By reporting the finding that the approval rate is between 2 and 3, the team might miss the root of the issue that causes disparities in the satisfaction of certain groups of users. </details>

### Interview Bias

**Interview bias** refers to a participant's perception of the interviewer. This may be due to a user's own biased perception of an interviewer's ethnicity, age, gender, or physical appearance &mdash; or even details like body language or facial expressions. Interview bias can be difficult to avoid, so it is just important to keep in mind when evaluating the data.

<details open>

<summary>Example</summary>

<br>

Imagine that a team of four researchers conducts user interviews. Three of the researchers are 25 years old and one researcher is 50 years old. All interview participants are 20-25 years old.

When reviewing the data, the team noticed a clear trend: participants who talked to the younger researchers shared detailed responses that indicated honesty and openness. By contrast, most participants who spoke with the older researcher shared little detail, and their responses indicated an unwillingness to share openly. In this case, participants may have held a bias against the older researcher, which impacted how they approached the interview. </details>

### Response Bias

**Response bias** is the tendency to consciously or subconsciously provide inaccurate information due to the nature of self-reporting. If the research study relies on self-reported data, it's important to keep in mind the limitations that come with it. For reasons that don't pertain to the design, the user response may be inaccurate or misleading. A user may misremember information, leave out details that would be important, or change their responses to portray a certain self-image.

<details open>

<summary>Example</summary>

<br>

If a survey asks, “How much time do you typically spend on a popular social media app every day?”, participants may not know the exact amount. Their guess could be inaccurate, or they may report a lower number if they feel guilty about spending too much time on social media. To minimize response bias in this scenario, researchers need a way to obtain more accurate data. Some phones automatically track how much time is spent on each app. Asking participants to reference the data tracked by their phone should lead to more accurate responses. </details>

### Social Desirability Bias

**Social desirability bias** is a tendency to provide answers that align with characteristics or viewpoints that the participant views as socially desirable. It is difficult to completely avoid these types of biases, as a participant will always know they are being interviewed, but researchers can minimize the effects by providing a comfortable environment, creating rapport and engaging in natural conversation throughout the interview, and keeping the participant's personal details anonymous.

<details open>

<summary>Example</summary>

<br>

Imagine that a researcher starts an interview with this question: “How often do you call your parents?” The participant may feel that they call their parents too frequently or infrequently. As a result, they might adjust their answer to match what they believe is normal or respectable.

To better lead into this topic, the interview could start with questions that are less personal, such as “In general, do you prefer texting or calling?” and “When you reach out to family members, how do you usually contact them?” Researchers should be mindful of topics that could spark social desirability bias. That way, they can carefully structure the study to help participants share openly and honestly. </details>
